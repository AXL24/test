import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.LongWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Mapper;

import java.io.IOException;

public class ElectricConsumptionMapper extends Mapper<LongWritable, Text, Text, IntWritable> {
    private Text year = new Text();
    private IntWritable averageConsumption = new IntWritable();

    @Override
    protected void map(LongWritable key, Text value, Context context) throws IOException, InterruptedException {
        // Tách các trường từ dòng dữ liệu
        String[] fields = value.toString().split("\t");
        if (fields.length > 0) {
            try {
                year.set(fields[0]); // Năm
                averageConsumption.set(Integer.parseInt(fields[fields.length - 1])); // Giá trị trung bình
                context.write(year, averageConsumption);
            } catch (NumberFormatException e) {
                // Bỏ qua nếu không thể chuyển đổi
            }
        }
    }
}
2.2. ElectricConsumptionReducer.java
java
Copy code
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Reducer;

import java.io.IOException;

public class ElectricConsumptionReducer extends Reducer<Text, IntWritable, Text, IntWritable> {
    private static final int MAX_CONSUMPTION = 30;
    private IntWritable result = new IntWritable();

    @Override
    protected void reduce(Text key, Iterable<IntWritable> values, Context context) throws IOException, InterruptedException {
        for (IntWritable val : values) {
            if (val.get() > MAX_CONSUMPTION) {
                result.set(val.get());
                context.write(key, result);
            }
        }
    }
}
2.3. ElectricConsumptionDriver.java
java
Copy code
import org.apache.hadoop.conf.Configuration;
import org.apache.hadoop.fs.Path;
import org.apache.hadoop.io.IntWritable;
import org.apache.hadoop.io.Text;
import org.apache.hadoop.mapreduce.Job;
import org.apache.hadoop.mapreduce.lib.input.FileInputFormat;
import org.apache.hadoop.mapreduce.lib.output.FileOutputFormat;

public class ElectricConsumptionDriver {
    public static void main(String[] args) throws Exception {
        if (args.length != 2) {
            System.err.println("Usage: ElectricConsumptionDriver <input path> <output path>");
            System.exit(-1);
        }

        Configuration conf = new Configuration();
        Job job = Job.getInstance(conf, "Electric Consumption Analysis");

        job.setJarByClass(ElectricConsumptionDriver.class);
        job.setMapperClass(ElectricConsumptionMapper.class);
        job.setReducerClass(ElectricConsumptionReducer.class);

        job.setOutputKeyClass(Text.class);
        job.setOutputValueClass(IntWritable.class);

        FileInputFormat.addInputPath(job, new Path(args[0]));
        FileOutputFormat.setOutputPath(job, new Path(args[1]));

        System.exit(job.waitForCompletion(true) ? 0 : 1);
    }
}
3. Hướng dẫn sử dụng
Cấu trúc thư mục:

css
Copy code
your_project/
├── src/
│   └── main/
│       └── java/
│           └── your_package/
│               ├── ElectricConsumptionMapper.java
│               ├── ElectricConsumptionReducer.java
│               └── ElectricConsumptionDriver.java
└── pom.xml (nếu sử dụng Maven)
Biên dịch chương trình: Sử dụng Maven hoặc Gradle để biên dịch chương trình và tạo tệp JAR.

Chạy chương trình: Sử dụng lệnh sau trên Hadoop:

bash
Copy code
hadoop jar ElectricConsumptionDriver.jar <input_path> <output_path>
Trong đó <input_path> là đường dẫn đến tệp dữ liệu đầu vào và <output_path> là đường dẫn đến thư mục đầu ra.

Kiểm tra kết quả: Kết quả sẽ được lưu trong thư mục đầu ra mà bạn đã chỉ định. Các năm có lượng điện tiêu thụ trung bình lớn hơn 30 sẽ được xuất ra cùng với giá trị tương ứng.

Với chương trình này, bạn đã hoàn thành việc phân tích tiêu thụ điện hàng năm cho tổ chức của mình. Nếu bạn cần thêm bất kỳ hỗ trợ nào, hãy cho tôi biết!
